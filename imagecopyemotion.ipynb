{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d303434-8c4a-4743-b5c9-77516444d563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6606d5b5-abca-4e4f-8655-27bd17318e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 492ms/step\n",
      "Detected emotion: Happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"--filename\",help=\"me.jpg\")\n",
    "filename = 'v1.jpg'\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "# prevents openCL usage and unnecessary logging messages\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "# dictionary which assigns each label an emotion (alphabetical order)\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "\n",
    "facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "frame = cv2.imread(filename)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "    prediction = model.predict(cropped_img)\n",
    "    maxindex = int(np.argmax(prediction))\n",
    "    detected_emotion = emotion_dict[maxindex]\n",
    "    print(f\"Detected emotion: {detected_emotion}\")\n",
    "    \n",
    "    cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "# cv2.imwrite('test_'+filename, cv2.resize(frame,(1600,960),interpolation = cv2.INTER_CUBIC))\n",
    "cv2.imwrite(f'test_{filename.split(\"/\")[-1]}', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82521b8c-bb06-4b91-82a1-0ea2e4da528d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def detect_emotion(filename):\n",
    "    ap = argparse.ArgumentParser()\n",
    "    # ap.add_argument(\"--filename\",help=\"me.jpg\")\n",
    "    ap.add_argument(\"--filename\", required=True, help=\"Path to the input image\")\n",
    "    args = ap.parse_args()\n",
    "    filename = args.filename\n",
    "    # filename = 'v10.jpg'\n",
    "\n",
    "\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.load_weights('model.h5')\n",
    "\n",
    "    # prevents openCL usage and unnecessary logging messages\n",
    "    cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "    # dictionary which assigns each label an emotion (alphabetical order)\n",
    "    emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "\n",
    "    facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    frame = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = facecasc.detectMultiScale(gray,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        prediction = model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        detected_emotion = emotion_dict[maxindex]\n",
    "        cv2.imwrite(f'test_{filename.split(\"/\")[-1]}', frame)\n",
    "        # print(f\"Detected emotion: {detected_emotion}\")\n",
    "    return detected_emotion\n",
    "    \n",
    "    # cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "# cv2.imwrite('test_'+filename, cv2.resize(frame,(1600,960),interpolation = cv2.INTER_CUBIC))\n",
    "        # cv2.imwrite(f'test_{filename.split(\"/\")[-1]}', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1063f2d6-c7e9-4dbe-b896-d18df49f5a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --filename FILENAME\n",
      "ipykernel_launcher.py: error: the following arguments are required: --filename\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sys.argv.append('C:/Users/shiva/Machine Leaning/v5.jpg')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = sys.argv[1]\n",
    "    detected_emotion = detect_emotion(image_path)\n",
    "    print(f\"Detected emotion: {detected_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df248352-5e00-4cfa-a641-af5c07161235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bb74e-c0fe-42a2-ad6a-19cf8331908a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
